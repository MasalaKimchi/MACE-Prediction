# Survival Analysis Experiment Configuration
# Based on SegFormer3D compartmentalized structure

# Dataset configuration
dataset:
  train_csv: "path/to/train.csv"
  val_csv: "path/to/val.csv"
  nifti_col: "NIFTI path"
  time_col: "time"
  event_col: "event"
  feature_cols: null  # Use all except nifti, time, event
  categorical_cols: null  # Auto-detect
  numerical_cols: null  # Auto-detect
  image_size: [256, 256, 64]
  use_cache: false
  augment: true
  cache_rate: 1.0
  num_workers: 4

# Model configuration
model:
  img_encoder: resnet3d        # or swin3d
  tab_encoder: mlp             # or ft_transformer
  embed_dim: 256

swin3d:
  feature_size: 48
  window_size: 7
  depths: [2, 2, 2, 2]
  num_heads: [3, 6, 12, 24]
  dropout_path_rate: 0.1

ft_transformer:
  n_heads: 4
  depth: 2
  dropout: 0.1
  num_numeric: 24
  cat_cardinalities: []

# Training configuration
training:
  batch_size: 6
  epochs: 50
  learning_rate: 1e-4
  weight_decay: 1e-5
  optimizer: "adamw"  # adamw, adam, sgd
  scheduler: "cosine"  # cosine, cosine_warm_restarts, onecycle, none
  eta_min: 1e-7  # Minimum learning rate for cosine scheduler
  max_grad_norm: 1.0  # Gradient clipping (0 to disable)
  freeze_epochs: 0  # Freeze encoder for N warmup epochs
  amp: false  # Mixed precision
  compile: false  # torch.compile

# Loss configuration
losses:
  use_torchsurv_cox: true
  lambda_cox: 1.0
  lambda_cpl: 0.5
  lambda_tmcl: 0.5
  cpl: { tau0: 1.0, kappa: 0.5 }
  tmcl: { mode: "triplet", pos_tau_months: 6, neg_tau_months: 24, beta_margin_per_year: 0.1, alpha_max: 0.5 }

# DataLoader configuration
dataloader:
  num_workers: 8
  pin_memory: true
  persistent_workers: true
  prefetch_factor: 4

# Sampler configuration
sampler:
  event_fraction: 0.5  # fraction of events per batch when using EventAwareBatchSampler

# Evaluation configuration
eval:
  horizons_years: [1,2,3,4,5]
  brier_grid_years: [0.5, 1, 2, 3, 4, 5]

early_stopping:
  metric: "val_cindex"
  mode: "max"
  patience: 10
  delta: 1.0e-4

# Logging configuration
logging:
  log_dir: "finetune_logs"
  output_path: "finetune_logs/finetuned_model.pth"
  tensorboard: true

# Wandb configuration (optional)
wandb:
  mode: "offline"  # offline, online
  entity: ""
  project: "survival-analysis"
  name: "survival_experiment"
